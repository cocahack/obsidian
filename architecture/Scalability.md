# 규모 확장성
## 초기 구성 - 단일 서버

서비스 초기에는 서비스에 필요한 모든 구성요소들이 단일 서버에 올라가는 형태일 수 있다. 웹 서버, WAS, DB, 캐시 저장소 등이 모두 같은 서버에서 구동되는 것이다.

## 첫 번째 확장 - DB

서비스가 성장하면서 요청 수가 점점 많아진다면 DB를 별도의 서버로 분리하는 방안을 고려할 수 있다.

### 데이터베이스 선택

데이터를 영구적으로(또는 장기간) 저장할 필요성이 있다면 데이터베이스를 사용해야 한다. 데이터베이스를 선정할 때 가장 먼저 RDBMS와 NoSQL 중 하나를 고민하게 될 것이다.

#### RDBMS

대부분의 사례에서는 RDBMS를 선택하는 것이 크게 문제가 되지 않는다. 트랜잭션으로 인해 트랜잭션이 없을 때 발생할 수 있는 사항을 애플리케이션에서 구현할 필요가 없으며, 인덱스로 원하는 데이터를 검색하기 용이하며, 잠금을 사용하여 일관성을 구현할 때 사용할 수도 있다. 또, 서비스가 커지면서 확장이 필요할 때는 replication으로 읽기 부하를 줄여볼 수 있고, 그보다도 더 커지게 된다면 파티셔닝 또는 샤딩으로 대처할 수 있다.

RDBMS에는 Oracle, MySQL, Postgre 등 오랜 기간동안 비즈니스에 이용되면서 검증된 제품들이 많이 있다. 어떤 제품을 사용할지는 비용과 서비스 개발 및 운영자들의 숙련도 등의 기준으로 결정하게 될 것이다.

#### NoSQL

NoSQL은 RDBMS와 대척점에 있으며, 다양한 저장소 형태가 있어 특수한 상황에서 적절하게 쓰일 수 있다.

자세한 내용은 [[nosql-core]] 참고.

## 두 번째 확장 - Scaling

적절한 데이터베이스를 선택하고 웹 과 앱 서버와 DB 서버를 분리해서 운영하여 늘어난 트래픽에 잘 대응했을 것이다. 그 결과로 서비스는 더 성장하게 되어 시스템 확장이 필요해졌다고 가정하자. 이럴 때 선택할 수 있는 방법은 두 가지이다. 바로 수직적 확장과 수평적 확장이다.

수직적 확장(scale up, vertical scaling)은 서버 장비의 사양을 확장하는 것을 말한다. 물리 서버를 사용하고 있다면 서버를 잠시 내리는 것이 필수적이며, VM을 사용하고 있다면 라이브 상태에서 사양을 업그레이드 하는 것이 가능하기는 하다. 그러나 안전하게 확장하기 위해서는 역시나 서버를 재시작하는 것이 좋다. 결국, 무중단 서비스에서 수직적 확장을 하기 위해서는 별도의 장치가 더 마련되어야 한다.

수평적 확장(scale out, horizontal scaling)은 더 많은 서버를 추가하여 성능을 개선한다. 예를 들어, 웹 서비스에서 너무 많은 유저가 접속할 경우, 로드 밸런서를 도입해볼 수 있다.

### Load balancer

로드밸런서는 load balancing set에 속한 서버에 트래픽을 골고루 분산시키는 역할을 한다.

로드밸런서는 외부에서 접근할 수 있는 엔드포인트를 노출하고 있다. 그 엔드포인트로 접근하면, 로드밸런서는 연결된 서버 중 하나로 요청을 포워딩한다. 이 때 로드밸런서와 서버 사이에는 대체로 사설 통신을 한다. 

#### Stateless web layer

앱 서버 앞에 로드밸런서를 두어 부하 분산을 하고 싶다면, 앱 서버는 stateless해야 한다. 같은 역할을 하는 앱 서버가 여러 개가 생기는데, 서버 내부에 유저와 관련된 상태를 저장하고 있다면 그 유저의 모든 요청은 같은 서버에만 전달되어야 하기 때문이다. 이를 가능하게 해주는 sticky session 기능이 로드밸런서에 포함되어 있는 경우가 많아 로드밸런서를 사용할 수 없는 것은 아니지만, 부하 분산이라는 본래 목적을 달성하기는 어렵다. 

예를 들어, 세션을 메모리에 저장하고 있다면 A 서버에 로그인한 유저는 항상 모든 요청을 A 서버로 할 수 있도록 만들어야 한다. 이렇게 상태를 가진 웹 서버는 수평 확장의 장애물이 된다.

상태를 분리하기 위해, 세션을 별도로 마련한 저장소에 저장하는 방법을 사용하거나, WAS가 세션 클러스터링을 지원할 경우 서로 다른 WAS일지라도 세션을 공유할 수 있게 만들 수 있다. 

이렇게 상태를 분리하고 나면 웹과 앱 서버는 auto scaling을 적용하여 트래픽에 따라 탄력적으로 확장할 수도 있다.

### 데이터베이스 다중화

웹, 앱 서버를 로드밸런서를 사용해 부하 분산을 처리했다면, 그 다음에는 저장소 차례이다. 웹과 앱 서버를 확장하여 많은 유저를 수용할 수 있다고 해도, 대부분 읽기와 쓰기 요청은 데이터베이스를 통할 수 밖에 없다. 결국 앞 단의 서버가 늘어났어도 데이터베이스는 그대로이므로 데이터베이스가 병목이 되는 것이다.

많은 데이터베이스들은 다중화를 지원한다. 보통 데이터베이스 서버들을 리더와 팔로워로 구분하며, 데이터 원본과 사본은 각각 리더와 팔로워에 저장하는 방식이다. 이렇게 구성하여 읽기 요청에 대한 부하 분산을 누릴 수 있으며, 하나의 팔로워에 문제가 발생해도 지속적인 서비스가 가능해진다.

## 세 번째 확장 - Caching

값비싼 연산의 결과나 자주 참조되는 데이터를 메모리 안에 두고, 그 다음 요청 시 이를 재활용하는 캐싱을 적용해 볼 수 있다. 이렇게 하면 데이터베이스로의 부하가 상당히 줄어들 수 있다. 

일반적으로 웹 서비스에서 캐시가 활용되는 흐름은 다음과 같다.

1. 데이터가 캐시에 있다면 캐시에서 데이터를 읽는다.
2. 데이터가 캐시에 없다면 데이터베이스에 접근하여 데이터를 읽어온 다음, 이를 캐시에 쓴다.

위와 같은 캐시 전략을 read-through caching strategy라고 한다. 그 밖에 다양한 캐시 전략은 [여기](caching-strategy)에서 설명한다.

### 유의할 점

캐싱은 성능을 개선하기 위해 사용할 수 있는 쉽고 강력한 수단이다. 하지만 모든 경우에 사용할 수 있는 것은 아니며, 적용하고 나서도 주의해야 할 점들이 있다.

- 캐싱은 Write보다 Read가 자주 일어나는 워크로드에 적합하다.
- 캐시는 메모리에 저장하기 때문에 영속성이 필요한 데이터는 데이터베이스에 저장해야 한다. 
- 캐시된 데이터를 교체하기 위한 만료 시각을 설정해야 한다. 너무 짧으면 데이터베이스를 자주 읽게 될 수 있고, 너무 길면 원본과 차이가 날 수 있다.
- 데이터 저장소의 원본과 캐시된 사본이 서로 같은지, 즉 일관성을 유지할 방법도 생각해야 한다. 원본 갱신 작업과 캐시 갱신 작업이 단일 트랜잭션으로 처리되지 않으면 일관성이 깨질 수 있다. 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하기는 어려울 수 있다(이와 관련된 내용은 Meta의 논문[^1] 참조).
- 캐시 서버를 한 대만 둘 경우 SPoF가 될 수 있다. 이를 피하기 위해서는 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.
- 캐시 메모리의 크기도 적절히 정해야 한다. 너무 작으면 엑세스 패턴에 따라 데이터가 자주 eviction되어 성능 저하가 발생할 수 있다.
- 데이터 eviction 정책도 결정해야 한다. 캐시가 꽉 찼을 때 어떤 데이터를 내보낼지에 따라 성능에 영향을 줄 수 있다. LRU, LFU 등의 정책이 있다.

### CDN(Content Delivery Network)

CDN은 정적 컨텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오와 각종 파일 등을 캐시할 수 있다. 

유저가 정적 컨텐츠를 요청할 때 서버로부터 응답을 받는 과정은 다음과 같다.

1. 유저는 컨텐츠 URL로 접근한다. URL의 도메인은 CDN 서비스 사업자가 제공한 것을 사용한다.
2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 원본 서버에 요청하여 파일을 가져온다.
3. 원본 서버가 CDN 서버에 컨텐츠 파일을 반환한다. 응답의 HTTP 헤더에는 파일이 얼마나 오래 캐시될 수 있는지를 설명하는 TTL(Time-To-Live) 값이 들어 있다.
4. CDN 서버는 파일을 캐시하고 유저에게 반환한다. 파일은 TTL에 명시된 시간이 끝날 때까지 캐시된다.
5. 다른 유저가 같은 컨텐츠를 요청한다.
6. 만료되지 않은 파일이라면 캐시로 요청을 처리한다.

#### 유의할 점

CDN을 사용할 때 유의할 점은 다음과 같다. 

1. 만료 시점을 적절히 정해야 한다.
2. CDN 서버에 장애가 발생했을 때 요청을 어떻게 처리할지도 판단해두어야 한다.
3. 컨텐츠 invalidation 방안을 고려해야 한다. CDN 서비스 사업자가 제공하는 API를 쓰거나, 오브젝트 버저닝 등을 사용할 수 있다.

## 네 번째 확장 - 데이터 센터

서비스가 더 성장하여 전국적으로 많은 트래픽이 발생하거나, 그걸 넘어서 전세계에서 발생하는 트래픽을 처리하게 될 수도 있다. 이럴 때는 여러 개의 데이터 센터를 사용하여 부하를 분산하면서, 유저에게는 낮은 레이턴시를 제공할 수 있다. 또한 데이터 센터가 여러 개이므로 하나의 데이터 센터에 장애가 발생해도 일시적으로 다른 데이터 센터에서 요청을 처리할 수 있다.

이런 아키텍처를 만들기 위해서는 해결해야할 문제가 있다.

1. 트래픽 우회: 효과적으로 트래픽을 데이터 센터로 전달하는 방법을 찾아야 한다. GeoDNS는 유저의 요청을 가장 가까운 데이터 센터로 트래픽을 보낼 수 있게 도와준다.
2. 데이터 동기화: 데이터 센터마다 별도의 데이터베이스를 사용하고 있다면, failover되어 트래픽이 다른 데이터 센터로 가도 찾는 데이터가 없을 수 있다. 이런 상황을 막기 위해서는 여러 데이터 센터에 걸쳐 다중화를 해야 한다.
3. 테스트와 배포: 아키텍처의 규모가 커질 수록 테스트와 배포는 어려워진다. 반드시 이를 자동화해야 한다.

### 메시지 큐

센터 간 데이터 동기화를 위해 메시지 큐를 사용해볼 수 있다. 

메시지 큐는 메시지의 무손실을 보장하고 비동기 통신을 지원한다. 한 데이터 센터에서 발생한 데이터를 큐를 통해 비동기적으로 다른 데이터 센터로 보내 지속적으로 동기화하는 아키텍처를 고안해볼 수도 있는 것이다.

또, 처리하는데 오래 걸리는 작업이나 이벤트 스트리밍에도 적용해볼 수 있다.

## 다섯 번째 확장 - Sharding

저장할 데이터가 많아지면 데이터베이스에 가해지는 부하도 증가한다. 단기적으로는 데이터베이스 서버를 scale up 해서 대처할 수 있지만, 데이터가 폭발적으로 증가하는 추세를 보인다면 scale out을 고려해야 한다.

데이터베이스의 scale out은 바로 샤딩이다. 대규모 데이터베이스를 샤드(shard)라고 부르는 작은 단위로 분할하며, 각 샤드는 같은 스키마를 쓰지만 데이터는 모든 샤드에서 유일하게 존재한다. 

샤딩 전략을 구현할 때 고려해야 할 가장 중요한 요소는 샤딩 키를 결정하는 것이다. 샤딩 키는 파티션 키라고도 부르며, 데이터를 어떻게 분산할지 결정하는 단서로 하나 이상의 컬럼으로 구성한다. 

샤딩으로 데이터베이스 규모를 확장할 수 있지만, 시스템이 복잡해지고 풀어야할 문제도 발생한다.

- Reshading(rebalancing과 같은지?): 데이터가 너무 많아져서 샤드를 늘려야 하거나, 샤드 간 데이터 분포가 고르지 못하여 어떤 샤드의 공간 소모가 빠르게 진행될 때 샤드 키를 계산하는 함수를 변경하고 데이터를 재배치해야 한다. 여기에 consistent hashing 기법을 사용해볼 수 있다.
- Celebrity 문제: 핫스팟 키 문제라고도 불린다. 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제다. 이 문제를 해결하기 위해 특정 키를 샤드하거나 잘게 쪼개야할 수도 있다.
- 조인과 비정규화: 데이터베이스를 여러 개로 쪼개면 여러 샤드에 걸친 데이터를 조인하기 어렵다. 스키마를 역정규화하여 하나의 테이블로 질의할 수 있는 방안을 고려해야 한다.





[^1]: [Scaling Memcache at Facebook](https://research.facebook.com/publications/scaling-memcache-at-facebook/)
