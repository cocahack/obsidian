# 처리율 제한 장치

클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치다. 이것을 사용할 때 얻는 이점은 다음과 같다.

- DoS 공격 방지
- 비용 절감
- 서버 과부하 차단


## 알고리즘

처리율 제한을 구현하기 위한 알고리즘에는 크게 다섯 가지가 있다.

- Token bucket
- Leaky bucket
- Fixed window counter
- Sliding window log
- Sliding window counter

### Token bucket

가장 직관적이면서도 효과적인 알고리즘이다. 

우선 버킷 크기와 토큰 공급률(refill rate) 두 개를 결정한다. 만약 버킷 크기가 3이고 분당 토큰 공급률이 3이라면, 1분마다 버킷에 담긴 토큰이 세 개가 되도록 유지하는 셈이다. 이후 요청이 들어오면 요청 당 토큰 하나를 사용한다. 만약 버킷에 토큰이 없을 때 요청이 들어온다면 처리가 불가능하다. 이 때 요청을 버리거나 큐에 임시로 쌓아두는 방식 등 필요에 따라 구현해볼 수 있다.

#### 장단점 

카운터로 쉽게 구현할 수 있다. 따라서 메모리도 덜 사용한다. 토큰이 있기만 하면 되기 때문에 짧은 시간 집중되는 트래픽(burst of traffic)도 잘 처리한다.

그러나 버킷 크기와 토큰 공급률 두 개의 파라미터를 적절히 튜닝하기가 까다롭다.

#### 구현

> [!Info]
> Redis로 구현하는 예시가 적힌 [글](https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/)을 참조했다.

가장 간단한 구현은 카운터를 쓰는 것이다. 요청이 오면 카운터를 1 감소시키면 된다. 그러나 버킷을 채워야 하는 시간에 도달했을 때, 그 순간 모든 버킷의 카운터를 변경해야하는 어려움이 있다. 

이를 해결하기 위해, 버킷이 마지막으로 채워진 시간의 타임스탬프를 별도의 키로 저장한다. 유저가 요청을 할 때 저장된 타임스탬프를 꺼내와 마지막 요청으로부터 몇 개의 토큰을 더 받을 수 있는지 계산한다. 이 알고리즘을 수행하고나서 새로운 토큰 카운터를 사용해 처리율 제한 기능을 유지하면 된다.

그러나 위의 방법에도 허점이 있다. 레디스에 쓰여진 값을 읽어와서 알고리즘을 수행한 뒤, 카운터를 변경해야 하므로 처리율 제한 장치가 여러 개 있다면 race condition 문제가 발생하게 된다. 락을 사용하는 방법은 성능 상 손해를 볼 수 있기 때문에 다른 방법을 선택해야 한다.

Redis에서 **sorted set** 자료구조를 사용하여 race condition 문제를 해결해볼 수 있다. 자세한 알고리즘은 다음과 같다. 

- 유저 당 정렬된 셋을 하나씩 부여하고 키와 값으로 요청을 시도했던 시간을 사용한다. 
- 유저가 보낸 요청을 받으면 제일 먼저 이전 인터벌 동안 발생했던 모든 요소를 제거한다. 이는 `ZREMRANGEBYSCORE` 커맨드를 사용하면 된다. 아마 `ZREMRANGEBYSCORE zset -inf (<CURRENT_INTERVAL_MILLISECONDS>` 를 쓰면 될 것 같다.
- `ZRANGE(0, -1)` 로 남아있던 모든 요소를 가져온다.
- 현재 타임스탬프를 `ZADD` 를 사용하여 셋에 넣는다.
- 위의 과정이 모두 끝나면 셋에 남아있는 요소의 개수를 가져와서 요청을 처리해도 되는지 판단할 수 있다.
- Set 에 처리율 제한 인터벌 시간을 TTL로 설정하면 요청을 하지 않는 유저의 셋을 제거하여 메모리를 최적화할 수 있다.

Redis의 `MULTI` 커맨드를 사용해 위의 과정을 원자적으로 수행할 수 있다. 

그러나 위 방법도 주의할 점이 있다. 차단된 요청도 요청으로 간주하기 때문에 어떤 유저가 계속해서 사용량을 초과하면, 가끔 요청이 허용되는 것이 아니라 한동안 완전히 차단될 수도 있다. 

### Leaky bucket

Token bucket 방식과 유사하다. 차이점은 요청 처리율이 고정되어있다는 점이며 이를 구현할 때 대부분 FIFO 큐를 사용한다. 동작원리는 다음과 같다.

- 요청이 도착했을 때 큐가 비어있으면 큐에 추가하고, 비어있지 않으면 요청은 버린다.
- 큐에 담긴 요청은 지정된 시간마다 꺼내어진다. 

이런 알고리즘에 따라 버킷 크기와 처리율(outflow rate) 이라는 두 개의 파라미터가 존재한다. 버킷 크기는 큐로 구현할 경우 큐의 크기라고 보면 된다. 처리율은 지정된 시간당 몇 개의 항목을 처리할지를 나타낸다. 

#### 장단점

큐의 크기가 제한되어 있어 정해진만큼 메모리를 쓸 수 있고, 고정된 처리율을 가지고 있어 안정적인 출력(stable outflow rate)에 적합하다.

그러나 단시간에 많이 트래픽이 몰리는 경우 큐에 오래된 요청이 쌓이게 되고, 이 요청이 제때 처리되지 않으면 최신 요청은 모두 버려진다. 또한 두 개의 파라미터를 튜닝하는 것이 까다롭다.

### Fixed window counter

타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 둬서 카운터가 임계치(threshold)에 도달하기 전까지 요청을 처리하는 방식이다. 요청 하나를 받을 때마다 윈도우의 카운터는 1 증가한다.

#### 장단점

카운터로 구현할 수 있어 메모리를 적게 사용하며, 특정 트래픽 패턴에 유리하다. 그러나 윈도우 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 최대 두 배의 트래픽을 처리하게 될 수도 있다는 큰 단점이 있다.

### Sliding window log

Fixed window counter의 매우 큰 단점은 이 방식으로 해결할 수 있다. 동작 방식은 다음과 같다.

- 요청의 타임스탬프를 이용한다. 보통 Redis의 sorted set에 저장한다.
- 새 요청이 오면 만료된 타임스탬프를 제거한다. 만료된 타임스탬프란 현재 윈도우의 시작 지점보다 오래된 것을 말한다.
-  새 요청의 타임스탬프를 로그에 추가한다.
-  로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 요청을 버린다.

#### 장단점

이 알고리즘을 사용하면 어느 시점의 윈도우를 겨냥하여 요청의 개수를 확인해도 항상 처리율 한도를 넘지 않는다.

그러나 처리되지 않은 요청의 타임스탬프까지 보관하기 때문에 메모리를 많이 필요로 한다.

### Sliding window counter

이 알고리즘은 Fixed window counter와 sliding window log 방식을 결합했다. 구현 방식은 두 가지가 있다.

#### 구현 방법 - 1

현재 윈도우에 몇 개의 요청을 받았다고 봐야하는지를 가정하여 계산하는 방식이다. 예를 들어, 윈도우가 11:59:40\~12:00:19 에 걸쳐있다고 볼 때, 직전 1분(11:59 경)에 걸쳐있는 비율은 대략 67%라고 볼 수 있다. 직전 1분 동안 9개, 그리고 현재 1분(정확히는 12:00\~12:19)에서 2개의 요청이 각각 들어왔다고 했을 때, 현재 윈도우에 들어온 요청 개수는 $9\times\frac{2}{3}+2$, 즉 8개로 봐야한다는 것이다.

> [!note]
> 비율 계산 시 소수점 처리는 선택사항이다. 계산 결과가 6.5개 일 때, 버림이나 내림, 반올림 등을 사용할 수 있다는 것이다.

#### 구현 방법 - 2

전체 윈도우 시간을 더 작은 버킷으로 나누는 방법이다. 각 버킷은 요청 카운트를 가지며, 버킷의 크기는 처리율 제한 장치에 어느 정도의 탄력성을 허용하냐에 따라 달라진다.

예를 들어, 시간 당 100개의 요청을 허용하는 처리율 제한장치를 구현한다고 가정해보자. 각 버킷의 사이즈를 20분으로 잡으면 단위 시간(1시간) 당 세 개의 버킷을 사용하는 것이다. 만약 오전 두 시부터 세 시까지 버킷이 다음과 같다고 가정해보자.

```
02:00 ~ 02:20 : 10
02:20 ~ 02:40 : 20
02:40 ~ 03:00 : 30
```

02:50에 요청이 하나 들어온다면 카운트된 전체 요청의 개수(60)는 100보다 작으므로 요청을 처리할 수 있다. 따라서 카운트는 다음과 같이 바뀐다.

```
02:00 ~ 02:20 : 10
02:20 ~ 02:40 : 20
02:40 ~ 03:00 : 31
```

> [!Note]
> 위 예제가 정확한 것은 아니다. 더 정확하게는 01:50 부터 02:50 까지의 인터벌을 고려해야 한다.

#### 장단점

이전 시간대의 평균 처리율을 고려하므로 짧은 시간에 몰리는 트래픽에도 잘 대응할 수 있고, 처리한 요청 개수만 카운트 형태로 보유하므로 메모리를 적게 사용한다.

그러나 첫 번째 구현 방법은 직전 시간대에 도착한 요청이 균등하게 분포되어 있다는 가정하에 추정치를 계산하므로 실제적으로는 오차가 존재한다는 단점이 있다(그러나 클라우드플레어에 따르면 오차로 인해 버려진 요청은 0.003%에 불과했다고 한다). 두 번째 방법도 처리된 요청 시각을 엄격하게 따지는게 아니므로 엄격한 처리율 제한이 필요한 경우에는 적합하지 않다.

## 설계하기

### 개략적인 설계 및 구현 방안

처리율 제한 장치는 클라이언트 측과 서버 측 모두 위치할 수 있다. 그러나 클라이언트 요청은 쉽게 위변조가 가능하기 때문에 서버 측에 두는 것이 더 안전하다. 클라이언트와 서버 사이에 미들웨어로 배치하는 것이 바람직할 것이다. 아키텍처에 API Gateway가 포함되어 있다면 여기에 두는 것이 좋을 것이다.

처리율 제한 장치를 구현할 때는 얼마나 많은 요청이 접수되었는지 추적할 수 있는 카운터를 대상마다 두어야 한다. 대상은 유저, IP, API 엔드포인트 등 서비스에 따라 다를 것이다. 

카운터 저장소는 읽고 쓰는 속도가 빠르고 만료 시간 등 부가적인 장치를 지원하면 좋을 것이다. 여기에는 Redis가 적절하다. 

정리하면, 처리율 제한 장치는 클라이언트와 서버 사이에 위치하며 Redis와 같은 카운터 저장소를 이용하여 구현한다. 단, 클라이언트와 서버 사이에 컴포넌트가 하나 더 생기는 것이므로 관리 요소가 되며, 따라서 SPoF가 발생하지 않도록 주의해야 할 것이다.

<span class='centerImg'> ![[rate-limit-architecture-outline.png]] </span>

### 상세 설계

#### 처리율 제한 규칙

단위 시간의 정의, 단위 시간 당 허용할 요청의 개수, 처리율 제한 대상 등 여러 항목에 대한 정의를 담아낼 수 있는 무언가가 필요하다. 이를 처리율 제한 규칙으로 추상화할 수 있다. 규칙을 기반으로 처리율 제한 장치의 동작을 제어하면 추후 정책 변경에 유리할 것이다.

CNCF의 Envoy 프로젝트가 사용하는 [ratelimit](https://github.com/envoyproxy/ratelimit) 프로젝트를 예로 들 수 있다. Yaml 형식의 Configuration 파일에 descriptor를 명시하는 방식이다.

```yaml
domain: <unique domain ID>
descriptors:
  - key: <rule key: required>
    value: <rule value: optional>
    rate_limit: (optional block)
      unit: <see below: required>
      requests_per_unit: <see below: required>
    shadow_mode: (optional)
    descriptors: (optional block)
      - ... (nested repetition of above)
```

#### 임계치에 도달한 이후 요청의 처리

처리율 제한에 걸린 요청은 HTTP 429(too many requests) 응답을 보내 처리한다. 구현에 따라서 요청을 큐에 보관했다가 나중에 처리할 수도 있다.

추가로, 처리율 제한 장치가 사용할만한 HTTP 헤더는 다음과 같다.

- `X-Ratelimit-Remaining`: 처리할 수 있는 요청의 수
- `X-Ratelimit-Limit`: 윈도우마다 클라이언트가 전송할 수 있는 요청의 수
- `X-Ratelimit-Retry-After`: 몇 초 뒤에 요청을 다시 보내야하는지를 나타냄

#### 분산 환경에서의 처리율 제한 장치

여러 대의 서버와 멀티 쓰레드를 지원하려면 race condition과 동기화 문제를 해결해야 한다.

##### Race condition

두 개 이상의 쓰레드가 같은 카운터를 읽은 뒤 수정하는 행위가 race condition을 유발한다. 가장 쉬운 해결 방법은 락을 사용하는 것이지만, 성능 상 문제가 있다. [[#Token bucket]] 에서 언급한 sorted set을 이용한 방식이나, Lua 스크립트를 사용하는 등 락을 회피하는 방법을 이용해볼 수 있다.

##### 동기화

처리율 제한 장치를 여러 개 둘 경우 동기화가 필요하다. 클라이언트가 보낸 요청이 첫 번째 처리율 제한 장치로 흘러 들어갔다가, 다음 요청에는 두 번째 처리율 제한 장치로 들어갔다면 제한 장치는 서로를 모르는 상태이기 때문에 올바른 처리율 제한이 불가하다. 

첫 번째로 Sticky session을 사용하는 방법이 있다. 항상 같은 처리율 제한 장치를 이용하면 동기화 문제는 발생하지 않을 것이다. 그러나 확장이 어려운 방법이므로 분산 환경에서는 적절하지 않다.

다른 방법으로는 Redis와 같은 데이터 저장소를 사용하는 방법이다.

##### 데이터센터 분산

Latency를 완화하기 위해 처리율 제한 장치도 여러 개의 데이터센터를 지원할 필요가 있다. 클라우드플레어는 edge server를 활용하여 유저의 요청을 가장 가까운 곳으로 보낼 수 있도록 한다.

##### 최종 일관성 모델

제한 장치 간 데이터 동기화를 위해 최종 일관성 모델을 사용해볼 수 있다. 엄격한 동기화는 성능 저하를 유발하므로, 이를 느슨하게 풀어 성능 최적화를 도모하는 것이다.

##### 모니터링

현재 적용되고 있는 처리율 정책과 알고리즘이 효과적으로 동작하고 있는지 파악하기 위해서는 모니터링이 필수다. 데이터를 분석하여 적절한 정책과 알고리즘을 선택해야 한다.

## 그 외 참고할만한 곳

- [서비스 가용성 확보에 필요한 Rate Limiting Algorithm에 대해](https://www.mimul.com/blog/about-rate-limit-algorithm/)